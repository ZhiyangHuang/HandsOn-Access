import os
import cv2
import numpy as np
import mediapipe as mp
import sys
import os
import math
from collections import deque
import win32api
import win32con
import threading
import time
from insightface.app import FaceAnalysis
import json

# ================== è„šæœ¬æ ¹ç›®å½• ==================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

# ================== Keyboard æ¨¡å—è·¯å¾„ ==================
keyboard_path = os.path.join(BASE_DIR, "../Keyboard")
if keyboard_path not in sys.path:
    sys.path.append(keyboard_path)
from vosk_recording import VoiceKeyboardSystem
from whisper_recording import RealTimeDictation
from speech_copy_win32 import ContinuousDictationController

# ================== é…ç½® ==================
USER_SETTING_FILE = os.path.join(BASE_DIR, "..", "user_setting.json")
if not os.path.exists(USER_SETTING_FILE):
    raise FileNotFoundError("âŒ æœªæ£€æµ‹åˆ° user_setting.jsonï¼Œç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œç¨‹åºé€€å‡ºã€‚")

with open(USER_SETTING_FILE, "r", encoding="utf-8") as f:
    USER_SETTINGS = json.load(f)

MODEL_PATH = os.path.join(BASE_DIR, "..", "Model", "face_landmarker.task")
USER_FACE_PATH = os.path.join(BASE_DIR, "..", "Initialization", "USER_FACE.npy")
# ================== æœ¬äººæ ¡éªŒçŠ¶æ€æœº ==================
STATE_NO_FACE = 0
STATE_VERIFYING = 1
STATE_LOCKED = 2
STATE_REJECT = 3

state = STATE_NO_FACE
SIM_THRESHOLD = 0.5

mouth_open_timer = None  # è®°å½•å˜´å·´å¼ å¼€çš„æ—¶é—´
mouth_triggered = False  # æ˜¯å¦å·²ç»è§¦å‘åŠ¨ä½œ
MOUTH_DELAY = 3         # å¼ å˜´å€’è®¡æ—¶ï¼Œå•ä½ç§’

app = FaceAnalysis(providers=['CUDAExecutionProvider'])
app.prepare(ctx_id=0, det_size=(640, 640))

face_present = False

mp_busy = False
latest_pts = None

# ---------------- å…¨å±€çŠ¶æ€ ----------------
mouse_state = {
    "current": None,   # None / "left_click" / "right_click" / "left_down"
    "down_time": None,
    "timer": None,
    "move_state": False,      # Move çŠ¶æ€
    "move_timer": None        # Move çŠ¶æ€å€’è®¡æ—¶çº¿ç¨‹
}
mouse_enabled = True  # True è¡¨ç¤ºé¼ æ ‡æ“ä½œå…è®¸ï¼ŒFalse è¡¨ç¤ºç¦æ­¢
mouse_state_lock = threading.Lock()  # ðŸ”’
landmarks_lock = threading.Lock()    # ðŸ”’
dictation_lock = threading.Lock()    # ðŸ”’

# =============== jsonçŠ¶æ€åˆ—è¡¨ ====================
try:
    with open(USER_SETTING_FILE, "r", encoding="utf-8") as f:
        user_settings = json.load(f)
except FileNotFoundError:
    user_settings = {}

def execute_action(is_active, function_name):
    global mouth_open_timer, mouth_triggered
    
    if function_name == "Left click" and is_active:
        if pitch_ratio > 0.07 or pitch_ratio < -0.07 or yaw_ratio > 0.07 or yaw_ratio < -0.07:
            return
        Right_Click()

    elif function_name == "Right click" and is_active:
        if pitch_ratio > 0.07 or pitch_ratio < -0.07 or yaw_ratio > 0.07 or yaw_ratio < -0.07:
            return
        Left_Click()

    elif function_name == "Drag":
        if is_active:
            Left_ClickDown()
        else:
            Left_ClickUp()

    elif function_name == "Keyboard":
        toggle_mouse(not is_active)
        current_time = time.time()
        if pitch_ratio > 0.07 or pitch_ratio < -0.07 or yaw_ratio > 0.07 or yaw_ratio < -0.07:
            with dictation_lock:  # ðŸ”’
                if is_active and dictation_system.paused:
                    # å˜´å·´å¼ å¼€ï¼Œå¼€å§‹æˆ–é‡ç½®å€’è®¡æ—¶
                    mouth_open_timer = current_time
                    mouth_triggered = False  # é‡ç½®è§¦å‘çŠ¶æ€
                    dictation_system.set_paused(False)  # å¼ å˜´å¤„ç†è¯­éŸ³
                elif not is_active and not dictation_system.paused:
                    if mouth_open_timer is not None:
                        elapsed = current_time - mouth_open_timer
                        if elapsed >= MOUTH_DELAY and not mouth_triggered:
                            dictation_system.set_paused(True)   # é—­å˜´æš‚åœå¤„ç†
                            mouth_triggered = True

# ---------------- é”®ç›˜æ€»å¼€å…³ ----------------
def vosk_test():
    return VoiceKeyboardSystem() # VOSK

def whisper_test(model):
    controller = ContinuousDictationController()
    dictation_system = RealTimeDictation(controller, model)
    return dictation_system# tiny / base / small / medium / large

def keyboard_controller():
    dictation_system = None
    if user_settings["voice_model"] == "VOSK":
        dictation_system = vosk_test()
    else:
        dictation_system = whisper_test(user_settings["voice_model"])
    return dictation_system
# 1. åˆ›å»ºæŽ§åˆ¶å™¨
dictation_system = keyboard_controller()
# åŽå°å¼€å¯
dictation_system.start()

# ---------------- é¼ æ ‡æ€»å¼€å…³ ----------------
def toggle_mouse(using_Mouse):
    """
    åˆ‡æ¢é¼ æ ‡æ“ä½œå¼€å…³
    """
    global mouse_enabled  # å£°æ˜Žæˆ‘ä»¬è¦ä¿®æ”¹å…¨å±€å˜é‡
    mouse_enabled = using_Mouse
    status = "å¼€å¯" if mouse_enabled else "æš‚åœ"
    #print(f"é¼ æ ‡æ“ä½œå·²{status}")

# ---------------- Move çŠ¶æ€ç®¡ç† ----------------
def start_move_timer():
    """
    å¯åŠ¨ 1 ç§’å€’è®¡æ—¶ï¼Œå¦‚æžœ 1 ç§’å†…æ²¡æœ‰åˆ·æ–°çŠ¶æ€åˆ™å–æ¶ˆ Move çŠ¶æ€
    """
    def timer_func():
        time.sleep(1)  # ç­‰å¾… 1 ç§’
        with mouse_state_lock:  # ðŸ”’
            # å¦‚æžœè¶…è¿‡ 1 ç§’æ²¡æœ‰åˆ·æ–°çŠ¶æ€ï¼Œå–æ¶ˆ Move çŠ¶æ€
            if mouse_state["move_state"]:
                mouse_state["move_state"] = False
                mouse_state["move_timer"] = None
                #print("Move çŠ¶æ€å·²å–æ¶ˆ")

    # å–æ¶ˆå·²æœ‰å€’è®¡æ—¶çº¿ç¨‹ï¼ˆå¦‚æžœæœ‰ï¼‰
    if mouse_state["move_timer"] is not None:
        # è¿™é‡Œç®€å•ä¸ç›´æŽ¥æ€çº¿ç¨‹ï¼Œä¸‹ä¸€è¡Œåˆ·æ–°çŠ¶æ€å³å¯
        mouse_state["move_timer"] = None

    # å¯åŠ¨æ–°å€’è®¡æ—¶çº¿ç¨‹
    t = threading.Thread(target=timer_func)
    t.start()
    with mouse_state_lock:  # ðŸ”’
        mouse_state["move_timer"] = t

def set_move_state():
    """
    è®¾ç½® Move çŠ¶æ€å¹¶åˆ·æ–°å€’è®¡æ—¶
    """
    with mouse_state_lock:  # ðŸ”’
        mouse_state["move_state"] = True
        #print("Move çŠ¶æ€å·²è§¦å‘")
    start_move_timer()

# ---------------- é¼ æ ‡ç§»åŠ¨å‡½æ•° ----------------
def Move_Up(pixels):
    if not mouse_enabled:  # å¦‚æžœè¢«ç¦ç”¨ï¼Œç›´æŽ¥è¿”å›ž
        return
    win32api.mouse_event(win32con.MOUSEEVENTF_MOVE, 0, -pixels, 0, 0)
    set_move_state()

def Move_Down(pixels):
    if not mouse_enabled:  # å¦‚æžœè¢«ç¦ç”¨ï¼Œç›´æŽ¥è¿”å›ž
        return
    win32api.mouse_event(win32con.MOUSEEVENTF_MOVE, 0, pixels, 0, 0)
    set_move_state()

def Move_Left(pixels):
    if not mouse_enabled:  # å¦‚æžœè¢«ç¦ç”¨ï¼Œç›´æŽ¥è¿”å›ž
        return
    win32api.mouse_event(win32con.MOUSEEVENTF_MOVE, -pixels, 0, 0, 0)
    set_move_state()

def Move_Right(pixels):
    if not mouse_enabled:  # å¦‚æžœè¢«ç¦ç”¨ï¼Œç›´æŽ¥è¿”å›ž
        return
    win32api.mouse_event(win32con.MOUSEEVENTF_MOVE, pixels, 0, 0, 0)
    set_move_state()

def Left_Click():
    with mouse_state_lock:  # ðŸ”’
        if not mouse_enabled:  # å¦‚æžœè¢«ç¦ç”¨ï¼Œç›´æŽ¥è¿”å›ž
            return
        if mouse_state["current"] is None and  not mouse_state["move_state"]:
            mouse_state["current"] = "left_click"
            win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, 0, 0, 0, 0)
            win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, 0, 0, 0, 0)
            mouse_state["current"] = None  # å®ŒæˆåŽé‡Šæ”¾çŠ¶æ€

def Right_Click():
    with mouse_state_lock:  # ðŸ”’
        if not mouse_enabled:  # å¦‚æžœè¢«ç¦ç”¨ï¼Œç›´æŽ¥è¿”å›ž
            return
        if mouse_state["current"] is None and  not mouse_state["move_state"]:
            mouse_state["current"] = "right_click"
            win32api.mouse_event(win32con.MOUSEEVENTF_RIGHTDOWN, 0, 0, 0, 0)
            win32api.mouse_event(win32con.MOUSEEVENTF_RIGHTUP, 0, 0, 0, 0)
            mouse_state["current"] = None

# è‡ªåŠ¨é‡Šæ”¾å‡½æ•°
def auto_release():
    time.sleep(10)  # ç­‰å¾…10ç§’
    with mouse_state_lock:
        # å¦‚æžœçŠ¶æ€ä»ç„¶æ˜¯ left_downï¼Œè‡ªåŠ¨é‡Šæ”¾
        if mouse_state["current"] == "left_down":
            #print("è‡ªåŠ¨é‡Šæ”¾ Left_ClickUpï¼ˆè¶…è¿‡10ç§’ï¼‰")
            win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, 0, 0, 0, 0)
            mouse_state["current"] = None
            mouse_state["down_time"] = None
            mouse_state["timer"] = None

# å·¦é”®æŒ‰ä¸‹
def Left_ClickDown():
    if not mouse_enabled:  # å¦‚æžœè¢«ç¦ç”¨ï¼Œç›´æŽ¥è¿”å›ž
        return
    with mouse_state_lock:
        if mouse_state["current"] is None:
            mouse_state["current"] = "left_down"
            mouse_state["down_time"] = time.time()
            win32api.mouse_event(win32con.MOUSEEVENTF_LEFTDOWN, 0, 0, 0, 0)
            # å¯åŠ¨è®¡æ—¶å™¨çº¿ç¨‹
            t = threading.Thread(target=auto_release)
            t.start()
            mouse_state["timer"] = t
            #print("Left_ClickDown å·²è§¦å‘")

# å·¦é”®é‡Šæ”¾
def Left_ClickUp():
    with mouse_state_lock:  # ðŸ”’
        if mouse_state["current"] == "left_down":
            win32api.mouse_event(win32con.MOUSEEVENTF_LEFTUP, 0, 0, 0, 0)
            mouse_state["current"] = None
            mouse_state["down_time"] = None
            mouse_state["timer"] = None
            #print("Left_ClickUp å·²æ‰‹åŠ¨é‡Šæ”¾")

# ================== MediaPipe åˆå§‹åŒ– ==================
BaseOptions = mp.tasks.BaseOptions
FaceLandmarker = mp.tasks.vision.FaceLandmarker
FaceLandmarkerOptions = mp.tasks.vision.FaceLandmarkerOptions
VisionRunningMode = mp.tasks.vision.RunningMode

latest_landmarks = None
landmarks_lock = threading.Lock()

def mp_callback(result, output_image, timestamp_ms):
    global latest_landmarks, face_present, mp_busy
    if result.face_landmarks:
        with landmarks_lock:  # ðŸ”’ åªä¿æŠ¤å…±äº«æ•°æ®
            latest_landmarks = result.face_landmarks[0]
            face_present = True
    else:
        with landmarks_lock:
            latest_landmarks = None
            face_present = False

    # âœ… æ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼Œå¿…é¡»é‡Šæ”¾ busy
    mp_busy = False

options = FaceLandmarkerOptions(
    base_options=BaseOptions(model_asset_path=MODEL_PATH, delegate="GPU"),
    running_mode=VisionRunningMode.LIVE_STREAM,
    result_callback=mp_callback,
    num_faces=1,
)

landmarker = FaceLandmarker.create_from_options(options)

# ================ æœ¬äººéªŒè¯å‡½æ•° ================
def cosine_similarity(a, b):
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

def verify_identity(frame):
    img_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    faces = app.get(img_rgb)
    if len(faces) == 0:
        return False, 0.0
    feature = faces[0].normed_embedding
    face_template = np.load(USER_FACE_PATH, mmap_mode='r')
    sim = cosine_similarity(feature, face_template)
    return sim > SIM_THRESHOLD, sim

# ================== å·¥å…·å‡½æ•° ==================
roll_history = deque(maxlen=5)
yaw_history = deque(maxlen=5)

def dist(a, b):
    return np.linalg.norm(np.array(a) - np.array(b))

def smooth_value(history_deque, new_value):
    history_deque.append(new_value)
    return sum(history_deque) / len(history_deque)

def calc_pair_angle(p_left, p_right):
    dx = p_right[0] - p_left[0]
    dy = p_right[1] - p_left[1]
    return math.degrees(math.atan2(dy, dx))

def compensate_roll(pts, roll_angle_deg, center_point):
    """ç»•ä¸­å¿ƒç‚¹åš roll è¡¥æ­£"""
    roll_rad = -math.radians(roll_angle_deg)
    cos_r, sin_r = math.cos(roll_rad), math.sin(roll_rad)
    cx, cy = center_point
    return [( (x-cx)*cos_r-(y-cy)*sin_r+cx, (x-cx)*sin_r+(y-cy)*cos_r+cy ) for x,y in pts]

def face_scale(pts):
    """è„¸éƒ¨å®½é«˜"""
    face_width = dist(pts[234], pts[454])
    face_height = dist(pts[10], pts[152])
    return face_width, face_height

# ================== å¤´éƒ¨å§¿æ€ ==================
def compute_head_pose(pts):
    left_eye, right_eye, nose = pts[33], pts[263], pts[1]
    left_ear, right_ear = pts[93], pts[323]
    left_face, right_face = pts[206], pts[426]

    # Roll
    roll = smooth_value(roll_history, 
                        (calc_pair_angle(left_eye, right_eye) +
                         calc_pair_angle(left_ear, right_ear) +
                         calc_pair_angle(left_face, right_face)) / 3)

    # ==== Roll è¡¥æ­£åŽçš„ç‚¹ ====
    left_eye_c, right_eye_c = compensate_roll([left_eye, right_eye], roll, nose)
    left_face_c, right_face_c = compensate_roll([left_face, right_face], roll, nose)

    # Yaw
    eye_center_x = (left_eye[0] + right_eye[0]) / 2
    face_width = abs(right_face[0]-left_face[0]) + 1e-6
    yaw_ratio = smooth_value(yaw_history, (nose[0]-eye_center_x)/face_width)

    # Pitch with Rollè¡¥æ­£
    top_y = (left_eye_c[1] + right_eye_c[1]) / 2
    bottom_y = (left_face_c[1] + right_face_c[1]) / 2
    pitch_ratio = (nose[1] - top_y) / (bottom_y - top_y + 1e-6)

    return roll, yaw_ratio, (pitch_ratio - 0.70)

# ================== åŠ¨ä½œæ£€æµ‹ ==================
def is_brow_raised(pts, roll_angle):
    nose = pts[1]
    left_pts = compensate_roll([pts[i] for i in [67,69,66,65]], roll_angle, nose)
    right_pts = compensate_roll([pts[i] for i in [300,302,301,297]], roll_angle, nose)
    left_eye_top = compensate_roll([pts[159]], roll_angle, nose)[0]
    right_eye_top = compensate_roll([pts[386]], roll_angle, nose)[0]

    left_ratio = (1/(abs(left_pts[2][1]-left_pts[1][1])+1e-6)) * abs(left_eye_top[1]-left_pts[0][1])
    right_ratio = (1/(abs(right_pts[2][1]-right_pts[1][1])+1e-6)) * abs(right_eye_top[1]-right_pts[0][1])
    ratio = (left_ratio + right_ratio)/2
    state = ratio > 2.6
    return ratio, state

def is_brow_frown(pts, roll_angle, face_height):
    nose = pts[1]
    # å·¦çœ‰ç‚¹
    left_pts = compensate_roll([pts[i] for i in [66,65,222,28,159,67,69]], roll_angle, nose)
    l66,l65,l222,l28,l159,l67,l69 = left_pts
    # å³çœ‰ç‚¹
    right_pts = compensate_roll([pts[i] for i in [296,295,443,258,386,300,302]], roll_angle, nose)
    r296,r295,r443,r258,r386,r300,r302 = right_pts

    left_shrink = abs(l66[1]-l222[1])/face_height
    left_eye_dist = abs(l159[1]-l66[1])/face_height
    right_shrink = abs(r296[1]-r443[1])/face_height
    right_eye_dist = abs(r386[1]-r296[1])/face_height

    shrink_ratio = (left_shrink+right_shrink)/2
    eye_ratio = (left_eye_dist+right_eye_dist)/2

    # ç«–çº¿è¾…åŠ©
    left_ratio = (1/(abs(l66[1]-l69[1])+1e-6))*abs(l159[1]-l67[1])
    right_ratio = (1/(abs(r300[1]-r302[1])+1e-6))*abs(r386[1]-r300[1])
    ratio = (left_ratio+right_ratio)/2

    frown_ratio = (1-shrink_ratio/0.045)+(1-eye_ratio/0.06)+ratio
    state = frown_ratio>0.4
    return frown_ratio, state

def is_lips_pout(pts, face_width, face_height):
    mouth_width = dist(pts[78], pts[308])
    mouth_height = dist(pts[13], pts[14])
    width_ratio = mouth_width / face_width
    height_ratio = mouth_height / face_height
    state = width_ratio < 0.25 and height_ratio < 0.03
    return (width_ratio, height_ratio), state

def is_mouth_open(pts, face_height):
    top, bottom = pts[13], pts[14]
    ratio = dist(top,bottom)/face_height
    return ratio, ratio>0.05

def detect_blink(pts, eye_idx, threshold=0.16):
    p_up = np.array(pts[eye_idx["up"]])
    p_down = np.array(pts[eye_idx["down"]])
    p_left = np.array(pts[eye_idx["left"]])
    p_right = np.array(pts[eye_idx["right"]])
    vertical_dist = np.linalg.norm(p_up - p_down)
    horizontal_dist = np.linalg.norm(p_left - p_right)
    ratio = vertical_dist / (horizontal_dist+1e-6)
    return ratio, ratio>threshold

# ================== ä¸»å¾ªçŽ¯ ==================
cap = cv2.VideoCapture(0)
timestamp = 0
#print("ðŸ“· å¼€å§‹å®žæ—¶æ£€æµ‹ï¼šq é”®é€€å‡º")

LEFT_EYE = {"up":159,"down":145,"left":33,"right":133}
RIGHT_EYE = {"up":386,"down":374,"left":362,"right":263}

while cap.isOpened():
    ret, frame = cap.read()
    if not ret: break
    h,w,_=frame.shape

    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB,
                        data=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
    if not mp_busy and timestamp % 4 == 0:   # åªå¤„ç† 7~8 FPS
        mp_busy = True
        landmarker.detect_async(mp_image, timestamp)
    timestamp+=1

    # ================== æœ¬äººæ ¡éªŒçŠ¶æ€æœº ==================
    if state == STATE_NO_FACE:
        cv2.putText(frame, "STATE: NO FACE", (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,255), 2)
        with landmarks_lock:  # ðŸ”’
            if face_present:
                state = STATE_VERIFYING
                #print("ðŸ‘€ æ£€æµ‹åˆ°äººè„¸ï¼Œè¿›å…¥èº«ä»½éªŒè¯")

    elif state == STATE_VERIFYING:
        cv2.putText(frame, "STATE: VERIFYING", (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,0), 2)
        ok, sim = verify_identity(frame)
        if ok:
            state = STATE_LOCKED
            #print(f"ðŸ”’ èº«ä»½ç¡®è®¤æˆåŠŸï¼Œç›¸ä¼¼åº¦: {sim:.2f}")
        else:
            state = STATE_REJECT
            #print(f"âŒ éžæœ¬äººï¼Œç›¸ä¼¼åº¦: {sim:.2f}")

    elif state == STATE_REJECT:
        cv2.putText(frame, "STATE: REJECT (NOT YOU)", (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,255), 2)
        state = STATE_NO_FACE

    elif state == STATE_LOCKED:
        cv2.putText(frame, "STATE: LOCKED (SAFE)", (20, 40),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)

        # ================== è¿™é‡Œå¼€å§‹ï¼šé¢éƒ¨å¼€å…³çš„é€»è¾‘ ==================
        with landmarks_lock:  # ðŸ”’
            latest_pts = [(int(lm.x*w), int(lm.y*h)) for lm in latest_landmarks] if latest_landmarks else None
            face_detected = face_present

        if latest_pts:
            roll, yaw_ratio, pitch_ratio = compute_head_pose(latest_pts)
            mouse_x = int(yaw_ratio*20)
            if yaw_ratio > 0.07:
                Move_Left(mouse_x)
            elif yaw_ratio < -0.07:
                Move_Right(-mouse_x)

            mouse_y = int(pitch_ratio*20)
            if pitch_ratio > 0.07:
                Move_Down(mouse_y)
            elif pitch_ratio < -0.07:
                Move_Up(-mouse_y)
            
            face_width, face_height = face_scale(latest_pts)
            brow_up_ratio,brow_up_state = is_brow_raised(latest_pts, roll)
            brow_frown_ratio,brow_frown_state = is_brow_frown(latest_pts, roll, face_height)
            lips_ratio, lips_pout_state = is_lips_pout(latest_pts, face_width, face_height)

            left_eye_ratio,left_eye_closed = detect_blink(latest_pts, LEFT_EYE)
            right_eye_ratio,right_eye_closed = detect_blink(latest_pts, RIGHT_EYE)
            
            mouth_ratio,mouth_open_state = is_mouth_open(latest_pts, face_height)
            
            action_states = {
                "pout": lips_pout_state,
                "mouth_open": mouth_open_state,
                "brow_up": brow_up_state,
                "brow_frown": brow_frown_state,
                "eye_close": not left_eye_closed or not right_eye_closed
            }
            
                
            for action_name, is_active in action_states.items():
                function_name = user_settings.get(action_name)
                if not function_name:
                    continue

                execute_action(is_active, function_name)

            # å¯è§†åŒ–
            cv2.putText(frame,f"Roll:{roll:.2f}",(10,30),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,0),2)
            cv2.putText(frame,f"Yaw:{yaw_ratio:.2f}",(10,60),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,0),2)
            cv2.putText(frame,f"Pitch:{pitch_ratio:.2f}",(10,90),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,255,0),2)

            cv2.putText(frame,f"Brow Raised:{brow_up_state} ({brow_up_ratio:.2f})",(10,120),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,200,200),2)
            cv2.putText(frame,f"Brow Frown:{brow_frown_state} ({brow_frown_ratio:.2f})",(10,150),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,200,200),2)
            cv2.putText(frame,f"Mouth Open:{mouth_open_state} ({mouth_ratio:.2f})",(10,180),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,200,255),2)
            cv2.putText(frame, f"Lips Pout: {lips_pout_state} ({lips_ratio[0]:.2f},{lips_ratio[1]:.2f})", (10, 210), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,200,200), 2)
            cv2.putText(frame,f"Left Eye Closed:{left_eye_closed} ({left_eye_ratio:.2f})",(10,240),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,200,255),2)
            cv2.putText(frame,f"Right Eye Closed:{right_eye_closed} ({right_eye_ratio:.2f})",(10,270),cv2.FONT_HERSHEY_SIMPLEX,0.7,(0,200,255),2)

        # å¦‚æžœæœ¬äººç¦»å¼€ï¼Œè‡ªåŠ¨å›žé”
        with landmarks_lock:  # ðŸ”’
            if not face_present:
                state = STATE_NO_FACE
                #print("ðŸ‘¤ æœ¬äººæ¶ˆå¤±ï¼Œå›žåˆ° NO_FACE çŠ¶æ€")

    cv2.imshow("Face Actions",frame)
    if cv2.waitKey(1)&0xFF==ord('q'):
        dictation_system.stop()
        break

cap.release()
cv2.destroyAllWindows()
landmarker.close()
#dictation_system.stop()
