import sounddevice as sd
import numpy as np
import threading
import queue
import time
import torch
import whisper

# =================== Whisper æ¨¡å‹åŠ è½½ ===================
def load_whisper_model_auto(model_name="tiny"):
    use_gpu = torch.cuda.is_available()
    device = "cuda" if use_gpu else "cpu"
    fp16 = use_gpu
    if not use_gpu:
        print("âš  æœªæ£€æµ‹åˆ° CUDA GPUï¼Œä½¿ç”¨ CPU + FP32")
    model = whisper.load_model(model_name)
    if use_gpu:
        model = model.to(device)
    return model, device, fp16

# =================== éŸ³é¢‘é‡‡é›†ç±» ===================
class AudioRecorder:
    def __init__(self, samplerate=16000, channels=1, block_duration=3):
        self.samplerate = samplerate
        self.channels = channels
        self.block_duration = block_duration

        self.q = queue.Queue(maxsize=10)
        self.audio_queue = queue.Queue(maxsize=5)

        self.running = False
        self.stream = None

        self.block_samples = int(samplerate * block_duration)
        self.audio_buffer = np.zeros((self.block_samples, channels), dtype=np.float32)
        self.write_pos = 0

        self.buffer_lock = threading.Lock()  # ğŸ”’

    def audio_callback(self, indata, frames, time_info, status):
        if status:
            print("Audio status:", status)
        try:
            self.q.put_nowait(indata.copy())
        except queue.Full:
            pass

    def start(self):
        if self.running:
            return
        self.running = True
        self.stream = sd.InputStream(
            samplerate=self.samplerate,
            channels=self.channels,
            callback=self.audio_callback
        )
        self.stream.start()
        threading.Thread(target=self._process_audio_loop, daemon=True).start()

    def stop(self):
        self.running = False
        if self.stream:
            self.stream.stop()
            self.stream.close()

    def _process_audio_loop(self):
        while self.running:
            try:
                data = self.q.get(timeout=0.1)
            except queue.Empty:
                continue

            data = data.astype(np.float32)
            frames = data.shape[0]
            read_pos = 0

            with self.buffer_lock:
                while frames > 0:
                    space = self.block_samples - self.write_pos
                    write_len = min(space, frames)

                    self.audio_buffer[
                        self.write_pos : self.write_pos + write_len
                    ] = data[read_pos : read_pos + write_len]

                    self.write_pos += write_len
                    read_pos += write_len
                    frames -= write_len

                    # buffer æ»¡ â†’ é€å…¥è¯†åˆ«é˜Ÿåˆ—
                    if self.write_pos >= self.block_samples:
                        audio_block = self.audio_buffer[:, 0].copy()

                        self.write_pos = 0

                        try:
                            self.audio_queue.put_nowait(audio_block)
                        except queue.Full:
                            try:
                                self.audio_queue.get_nowait()
                                self.audio_queue.put_nowait(audio_block)
                            except queue.Empty:
                                pass

# =================== Whisperè¯†åˆ«å™¨ ===================
class WhisperRecognizer:
    def __init__(self, model):
        self.model = model
        self.lock = threading.Lock()

    def recognize(self, audio_block):
        with self.lock:
            result = self.model.transcribe(audio_block, language="en")
        return result.get("text", "").strip()

# =================== æ™ºèƒ½å»¶è¿Ÿå¼€å…³ ===================
class SmartToggle:
    def __init__(self, delay=4.0):
        self.active = False          # å½“å‰æ˜¯å¦ start() æ¿€æ´»
        self.delay = delay
        self.last_trigger_time = None  # start() æœ€åè§¦å‘æ—¶é—´
        self.stop_trigger_time = None  # stop() ç¬¬ä¸€æ¬¡è§¦å‘æ—¶é—´
        self.lock = threading.Lock()  # ğŸ”’

    def trigger_on(self):
        """start() åˆ·æ–°æ¿€æ´»çŠ¶æ€"""
        with self.lock:  # ğŸ”’
            self.active = True
            self.last_trigger_time = time.time()
            self.stop_trigger_time = None  # start() æ—¶æ¸…ç©ºå»¶è¿Ÿè®¡æ—¶

    def trigger_off(self):
        """stop() è§¦å‘å»¶è¿Ÿå…³é—­ï¼Œåªè®°å½•ç¬¬ä¸€æ¬¡"""
        with self.lock:  # ğŸ”’
            if self.stop_trigger_time is None:
                self.stop_trigger_time = time.time()
            self.active = False

    def is_active(self):
        with self.lock:  # ğŸ”’
            if self.active:
                return True
            if self.stop_trigger_time is None:
                return False
            # å»¶è¿Ÿè¿˜æ²¡è¿‡
            return (time.time() - self.stop_trigger_time) < self.delay

    def deactivate(self):
        with self.lock:  # ğŸ”’
            self.active = False
            self.last_trigger_time = None
            self.stop_trigger_time = None

# =================== å®æ—¶è¯­éŸ³å¬å†™æ§åˆ¶å™¨ ===================
class RealTimeDictation:
    def __init__(self, controller = None, model="tiny", block_duration=3, delay=3.0):
        self.controller = controller
        model, device, fp16_flag = load_whisper_model_auto(model)  # å¯æ¢æˆ base / small / medium
        self.recognizer = WhisperRecognizer(model)
        self.audio_recorder = AudioRecorder(block_duration=block_duration)
        self.running = False
        self.paused = False
        self.lock = threading.Lock()
        self.delay = delay
        self._pause_thread = None
        self._pause_thread_lock = threading.Lock()

        # å¼‚æ­¥è¯†åˆ«çº¿ç¨‹
        self._worker_thread = threading.Thread(target=self._recognize_worker, daemon=True)
        self._worker_thread.start()

        self.string_only_mode = False
        if controller is None or controller is True:
            self.string_only_mode = True

        self.outprint = None

    # å¼‚æ­¥è¯†åˆ«çº¿ç¨‹
    def _recognize_worker(self):
        while True:
            if not self.running:
                time.sleep(0.1)
                continue
            try:
                audio_block = self.audio_recorder.audio_queue.get(timeout=0.1)
            except queue.Empty:
                continue

            with self.lock:
                if self.paused:
                    continue

            try:
                text = self.recognizer.recognize(audio_block)
                if text:
                    if self.string_only_mode:
                        self.outprint = text
                    else:
                        self.controller.on_new_recognized_text(text)
            except Exception as e:
                #print("Whisperè¯†åˆ«å¼‚å¸¸:", e)
                pass

    # ---------------- å¯åŠ¨ ----------------
    def start(self):
        with self.lock:
            if self.running:
                return
            self.running = True
        if not self.string_only_mode:
            self.controller.start()
        self.audio_recorder.start()

    # ---------------- åœæ­¢ï¼ˆå¸¦å»¶è¿Ÿåœç”¨ï¼‰ ----------------
    def stop(self):
        with self.lock:
            self.paused = True
        threading.Thread(target=self._delayed_stop_thread, daemon=True).start()

    def _delayed_stop_thread(self):
        stop_time = time.time()
        while True:
            time.sleep(0.1)
            with self.lock:
                if not self.paused:
                    return  # è¢« resume äº†
                if time.time() - stop_time >= self.delay:
                    break
        if not self.string_only_mode:
            self.controller.stop()
        self.audio_recorder.stop()
        with self.lock:
            self.running = False

    # ---------------- ç»Ÿä¸€æš‚åœ/æ¢å¤ ----------------
    def set_paused(self, paused: bool):
        with self.lock:
            if self.paused == paused:
                return
            self.paused = paused

        if paused:
            # å»¶è¿Ÿçº¿ç¨‹ç®¡ç†
            with self._pause_thread_lock:
                if self._pause_thread is None or not self._pause_thread.is_alive():
                    def delayed_pause():
                        start_time = time.time()
                        while True:
                            time.sleep(0.1)
                            with self.lock:
                                if not self.paused:
                                    return
                                if time.time() - start_time >= self.delay:
                                    break
                        if not self.string_only_mode:
                            self.controller.pause()
                    self._pause_thread = threading.Thread(target=delayed_pause, daemon=True)
                    self._pause_thread.start()
        else:
            if not self.string_only_mode:
                self.controller.resume()
